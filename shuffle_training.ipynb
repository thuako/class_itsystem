{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shuffle_training.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUDSqF9+mZuB0oAdyBHKdy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjrgh822/class_itsystem/blob/master/shuffle_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01RCqOlgd2ZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from numpy import expand_dims\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator( width_shift_range=3, \n",
        "                             height_shift_range=3, \n",
        "                             horizontal_flip=True, \n",
        "                             vertical_flip=True,\n",
        "                             brightness_range = [0.2, 1.0],\n",
        "                             rotation_range = 90,\n",
        "                             zoom_range = [0.5, 1.0]\n",
        "                             )\n",
        "                             \n",
        "\n",
        "nodatagen = ImageDataGenerator()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg_Np91-nulZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omIn21v-wEa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.load(\"/content/drive/My Drive/shuffledata_x.npy\")\n",
        "y_train = np.load(\"/content/drive/My Drive/shuffledata_y.npy\")\n",
        "y_train = np.argmax(y_train, axis=1).reshape(-1, 1)\n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUGJqvKdoCIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "def onehotencoding(data, case):\n",
        "  encoding = np.eye(case)[data]\n",
        "  return encoding.reshape(-1, case)'''\n",
        "\n",
        "'''y_train = np.argmax(y_train, axis=1).reshape(-1, 1)\n",
        "y_train.shape\n",
        "argu_y_test = np.argmax(argu_y_test, axis=1).reshape(-1, 1)'''\n",
        "\n",
        "argu= datagen.flow(x_test.reshape(-1, 28, 28, 1), y_test, batch_size = x_test.shape[0], shuffle=False)\n",
        "\n",
        "argu_y_test = argu[0][1]\n",
        "argu_x_test = argu[0][0].reshape(-1, 28, 28, 1)\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "argu_y_test = keras.utils.to_categorical(argu_y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VjdnsjRr4BY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"{x_train.shape}, {y_train.shape}\\n{argu_x_test.shape}, {argu_y_test.shape}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXoRQyPjeaU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    argu_x_test = argu_x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    argu_x_test = argu_x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(28,28,1), kernel_size=(11,11), padding=\"valid\", activation = \"relu\"))\n",
        "# Max Pooling\n",
        "model.add(MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"valid\"))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding=\"same\", activation = \"relu\"))\n",
        "# Max Pooling\n",
        "model.add(MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"valid\"))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# Passing it to a Fully Connected layer\n",
        "model.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "model.add(Dense(units = 2048, activation = \"relu\"))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# 3rd Fully Connected Layer\n",
        "model.add(Dense(1024, activation = \"relu\"))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(10, activation = \"softmax\")) #As we have two classes\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c-TMtrpeU8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "\n",
        "checkpointer = ModelCheckpoint(\n",
        "    filepath='model_2.h5',\n",
        "    save_best_only=True\n",
        ")\n",
        "early_stopping = EarlyStopping(patience=2)\n",
        "\n",
        "callbacks=[checkpointer, early_stopping]\n",
        "\n",
        "model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "          steps_per_epoch = x_train.shape[0]/ batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(argu_x_test, argu_y_test),\n",
        "          validation_steps = y_train.shape[0]\n",
        "          )\n",
        "\n",
        "#score = model.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aPe-B2E0jp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, LearningRateScheduler\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k43OvPRiW_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPTDGr62iXiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('model_2.h5')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('model_2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VregN080jGKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}