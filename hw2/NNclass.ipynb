{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_num = 100\n",
    "variance = 0.5\n",
    "wtflag = 0\n",
    "learning_rate = 0.2\n",
    "file_exist = False\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "# making dataset\n",
    "\n",
    "\n",
    "def making_data_set():\n",
    "    d_set = np.empty(1)\n",
    "    if file_exist:\n",
    "        tmp = np.load(sys.argv[1])\n",
    "        d_set = np.append(d_set, tmp)\n",
    "    else:\n",
    "        prob = rd.randint(0, 8, dataset_num)\n",
    "        for i in prob:\n",
    "            b0 = int(i/2)\n",
    "            b1 = int(b0/2)\n",
    "            b2 = int(b1/2)\n",
    "            \n",
    "            x = rd.normal(b0*2 - 1, variance)\n",
    "            y = rd.normal(b1*2 -1, variance)\n",
    "            z = rd.normal(b2*2-1, variance)\n",
    "            \n",
    "            result = b0 + b1 + b2\n",
    "            \n",
    "            rb0 = int(result/2)\n",
    "            rb1 = int(rb0/2)\n",
    "            \n",
    "            '''x = rd.randint(0, 2)\n",
    "            y = rd.randint(0, 2)\n",
    "            rst = x | y'''\n",
    "            d_set = np.append(d_set, [[x, y, z, rb0, rb1]])\n",
    "        if wtflag == 1:\n",
    "            np.save('dataset.npy', d_set)\n",
    "    d_set = np.delete(d_set, 0, axis=0)\n",
    "    d_set = d_set.reshape(-1, 5)\n",
    "    return d_set\n",
    "t_data = making_data_set()\n",
    "t_x_data = t_data[:, 0:-2]\n",
    "t_y_data = t_data[:, -2:].reshape(-1, 2)\n",
    "\n",
    "test_data = making_data_set()\n",
    "test_x_data = t_data[:, 0:-2]\n",
    "test_y_data = t_data[:, -2:].reshape(-1, 2)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class layer_class:\n",
    "    w = np.array([]); bias = 'False'; b = np.array([]);  dataflow = np.array([]);  delta = np.array([]);  y_ = 0\n",
    "    def __init__(self, w, bias='False'):\n",
    "        self.w = w\n",
    "        if bias == 'True':\n",
    "            self.bias = 'True'\n",
    "            self.b = np.zeros((1, w.shape[1]))\n",
    "        else:\n",
    "            self.bias = 'False'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs : 0\t train_loss :0.46158\t test_loss :0.46158, accuracy :65.5\n",
      "epochs : 1\t train_loss :0.43965\t test_loss :0.44238, accuracy :65.5\n",
      "epochs : 2\t train_loss :0.43114\t test_loss :0.43393, accuracy :65.5\n",
      "epochs : 3\t train_loss :0.42788\t test_loss :0.43005, accuracy :38.5\n",
      "epochs : 4\t train_loss :0.42658\t test_loss :0.4281, accuracy :38.5\n",
      "epochs : 5\t train_loss :0.42604\t test_loss :0.42701, accuracy :38.5\n",
      "epochs : 6\t train_loss :0.4258\t test_loss :0.42633, accuracy :38.5\n",
      "epochs : 7\t train_loss :0.42567\t test_loss :0.42587, accuracy :38.5\n",
      "epochs : 8\t train_loss :0.42557\t test_loss :0.42551, accuracy :38.5\n",
      "epochs : 9\t train_loss :0.42547\t test_loss :0.42521, accuracy :38.5\n",
      "epochs : 10\t train_loss :0.42537\t test_loss :0.42495, accuracy :38.5\n",
      "epochs : 11\t train_loss :0.42524\t test_loss :0.42471, accuracy :38.5\n",
      "epochs : 12\t train_loss :0.42511\t test_loss :0.42448, accuracy :38.5\n",
      "epochs : 13\t train_loss :0.42496\t test_loss :0.42426, accuracy :38.5\n",
      "epochs : 14\t train_loss :0.42479\t test_loss :0.42404, accuracy :38.5\n",
      "epochs : 15\t train_loss :0.42462\t test_loss :0.42383, accuracy :38.5\n",
      "epochs : 16\t train_loss :0.42444\t test_loss :0.42361, accuracy :38.5\n",
      "epochs : 17\t train_loss :0.42426\t test_loss :0.4234, accuracy :38.5\n"
     ]
    }
   ],
   "source": [
    "class NN:\n",
    "    train_set_x, train_set_y, test_set_x, test_set_y, learning_rate,  activate = np.array([]),np.array([]),np.array([]),np.array([]), 0, 'sigmoid'\n",
    "    layer, train_loss, test_loss, accuracy = [], [], [], []\n",
    "    feature = []\n",
    "    \n",
    "    #추적\n",
    "    weight_hist = []\n",
    "    delta_hist = []\n",
    "    bias_hist = []\n",
    "    def __init__(self, train_set_x, train_set_y, test_set_x, test_set_y, feature, learning_rate=0.01, activate='sigmoid'):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activate = activate\n",
    "        self.train_set_x = train_set_x\n",
    "        self.train_set_y = train_set_y\n",
    "        self.test_set_x = test_set_x\n",
    "        self.test_set_y = test_set_y\n",
    "        self.feature = feature\n",
    "        \n",
    "        # w initialization sigmoid use xavier initialization  Relu using He initialization\n",
    "        for i, f in enumerate(self.feature):\n",
    "            if i == (len(self.feature)-1):\n",
    "                break\n",
    "            w = 0\n",
    "            if f[2] is 'sigmoid':\n",
    "                w = rd.randn(f[0], int(self.feature[i + 1][0]))* np.sqrt(1/(f[0]+self.feature[i + 1][0]))\n",
    "            elif f[2] is 'relu':\n",
    "                w = rd.randn(f[0], int(self.feature[i + 1][0])) * np.sqrt(2/(f[0]+self.feature[i + 1][0])) \n",
    "            self.layer.append(layer_class(w, f[1]))\n",
    "\n",
    "    def sigmoid(self, a):\n",
    "        return 1/(1 + np.exp(-a)) \n",
    "    def relu(self, a):\n",
    "        a = a if a > 0 else 0\n",
    "        return a\n",
    "    def dsigmoid(self, a):\n",
    "        return a * (1 - a)\n",
    "    def drelu(self, a):\n",
    "        if a > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # forwarding\n",
    "    def pri(self):\n",
    "        for i in self.layer:\n",
    "            print(i.w)\n",
    "        print(\"\\n\", self.layer[0].dataflow)\n",
    "\n",
    "    def forwarding(self):\n",
    "        ftn = 0\n",
    "        if self.activate == 'sigmoid':\n",
    "            ftn = self.sigmoid\n",
    "        elif self.activate == 'relu':\n",
    "            ftn = self.relu\n",
    "\n",
    "        for i, k in enumerate(self.layer):\n",
    "            a = np.array([])\n",
    "            if i is 0:\n",
    "                a = np.append(a, np.dot(self.train_set_x, k.w))\n",
    "            else:\n",
    "                a = np.append(a, np.dot(self.layer[i-1].dataflow, k.w))\n",
    "            \n",
    "            a = a.reshape(self.train_set_x.shape[0], k.w.shape[1])\n",
    "            \n",
    "            if k.bias == 'True':\n",
    "                #print(f\"ones : {type(np.ones(1))}  bias : {type(k.b)}\")\n",
    "                a = np.multiply(np.ones((int(self.train_set_x.shape[0]), int(k.w.shape[1]))) , k.b) + a\n",
    "                #print(a)\n",
    "                \n",
    "            k.dataflow = ftn(a)\n",
    "            \n",
    "        #print(f\"predic output : {self.layer[-1].dataflow.shape}\\n data output : {self.train_set_y.shape}\")\n",
    "        self.train_loss = np.append(self.train_loss, np.average((self.layer[-1].dataflow - self.train_set_y) ** 2))\n",
    "\n",
    "        for i, k in enumerate(self.layer):\n",
    "            a = np.array([])\n",
    "            if i is 0:\n",
    "                a = np.append(a, np.dot(self.test_set_x, k.w))\n",
    "            else:\n",
    "                a = np.append(a, np.dot(self.layer[i-1].dataflow, k.w))\n",
    "            a = a.reshape(self.test_set_x.shape[0], k.w.shape[1])\n",
    "            k.dataflow = ftn(a)\n",
    "        self.test_loss = np.append(self.test_loss, np.average((self.layer[-1].dataflow - self.train_set_y) ** 2))\n",
    "\n",
    "\n",
    "    def backpropagation(self):\n",
    "        dftn = 0\n",
    "        if self.activate == 'sigmoid':\n",
    "            dftn = self.dsigmoid\n",
    "        elif self.activate == 'relu':\n",
    "            dftn = self.drelu\n",
    "\n",
    "\n",
    "        for i, L in reversed(list(enumerate(self.layer))):\n",
    "            '''summation {}{j} wij delatj 교재 slide 12p'''\n",
    "\n",
    "            # fully connected layer\n",
    "            if i is (len(self.layer)-1):\n",
    "                L.delta = np.multiply((self.train_set_y - L.dataflow), dftn(L.dataflow))\n",
    "                #print(f\"$$$$$$$$$i :{i}, L.dataflow : {L.dataflow.shape} L.delta : {L.delta.shape}, L.w : {L.w.shape}\")\n",
    "            #else\n",
    "            else:\n",
    "                back_L = self.layer[i+1]\n",
    "                L.delta = np.multiply(dftn(L.dataflow), np.dot(back_L.delta, back_L.w.T))\n",
    "                # print(f\"L.delta 구하는 과정\\n\\ni :{i}, L.dataflow : {L.dataflow.shape} back_L.delta : {back_L.delta.shape}, back_L.w : {back_L.w.shape}, L.w. : {L.w.shape}\\n 구하기 end \\n\\n\")\n",
    "\n",
    "            # i가 0 이면 input data가 train_set\n",
    "            if i is 0 :\n",
    "                input = self.train_set_x\n",
    "            else:\n",
    "                input = self.layer[i - 1].dataflow\n",
    "\n",
    "            '''x_k * delta -> upgrade할 weight '''\n",
    "            upgrade_w = np.zeros(1)\n",
    "            #outer로 한꺼번에 추가후에, reshape로 정렬\n",
    "            for k in range(L.delta.shape[0]):\n",
    "                upgrade_w = np.append(upgrade_w, np.outer(input[k], L.delta[k]))\n",
    "                #print(f\" for {i} layer **********************\\ndelta : \\n{L.delta[k]}\\n input : \\n{input[k]}\\n result : \\n{np.outer(input[k], L.delta[k])}\")\n",
    "            upgrade_w = np.delete(upgrade_w, 0, axis=0)\n",
    "            upgrade_w = upgrade_w.reshape(-1, L.w.shape[0], L.w.shape[1])\n",
    "            \n",
    "            self.delta_hist.append(L.delta.reshape(-1))\n",
    "            \n",
    "            if i == 0:\n",
    "                self.weight_hist.append(L.w.reshape(-1))\n",
    "            if L.bias is \"True\":\n",
    "                self.bias_hist.append(L.b.reshape(-1))\n",
    "            \n",
    "            \"\"\"weight update\"\"\"\n",
    "            if L.bias == 'True':\n",
    "                L.b = L.b + np.average(L.delta, axis=0)\n",
    "            \n",
    "            \"\"\"update weight\"\"\"\n",
    "            L.w = L.w + np.average(upgrade_w, axis=0) * self.learning_rate\n",
    "            \n",
    "            \n",
    "\n",
    "    def training(self, epochs):\n",
    "        for i in range(epochs):\n",
    "            self.forwarding()\n",
    "            self.backpropagation()\n",
    "            \n",
    "            cnt = np.array(np.abs(self.test_set_y  - np.add(self.layer[-1].dataflow, -0.2)) < 0.4 )\n",
    "            #print(f\"ny_data : \\n{test_y_data}\\n\\n y^ : \\n{self.layer[-1].dataflow}\")\n",
    "            correct = np.average(cnt) * 100\n",
    "            self.accuracy.append(correct)\n",
    "            #print(f\"bias : {self.layer[0].b}\")\n",
    "            print(f\"epochs : {i}\\t train_loss :{self.train_loss[i]:.5}\\t test_loss :{self.test_loss[i]:.5}, accuracy :{correct}\")\n",
    "\n",
    "    def plot(self):\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.train_loss, 'b')\n",
    "        plt.plot(self.test_loss, 'r')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.accuracy)\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.weight_hist)\n",
    "        plt.plot(self.delta_hist)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(self.bias_hist)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "test = NN(t_x_data, t_y_data, test_x_data, test_y_data, [[3, 'True', 'sigmoid'],[100, 'True', 'sigmoid'], [100, 'True', 'sigmoid'],[2, 'False', 'sigmoid']], learning_rate=learning_rate)\n",
    "\n",
    "test.training(epochs)\n",
    "test.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
