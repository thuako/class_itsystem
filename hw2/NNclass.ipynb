{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x test data : \n",
      "(100, 3)\n",
      " y test data : \n",
      " (100, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "dataset_num = 800\n",
    "variance = 0.4\n",
    "wtflag = 0\n",
    "file_exist = False\n",
    "\n",
    "\n",
    "'''dataset_num = 100\n",
    "variance = 0.5\n",
    "wtflag = 0\n",
    "learning_rate = 0.2\n",
    "file_exist = False\n",
    "\n",
    "epochs = 500  -> 75%\n",
    "[[3, 'True', 'relu'],[50, 'True', 'relu'], [50, 'True', 'relu'], [2, 'False', 'sigmoid']]\n",
    "\n",
    "\n",
    "dataset_num = 80\n",
    "variance = 0.5\n",
    "wtflag = 0\n",
    "learning_rate = 0.5\n",
    "file_exist = False\n",
    "\n",
    "epochs = 1200\n",
    "test = NN(t_x_data, t_y_data, test_x_data, test_y_data, [[2, 'True', 'relu'],[30, 'True', 'relu'],[30, 'True', 'relu'], [30, 'True', 'relu'], [1, 'False', 'sigmoid']], learning_rate=learning_rate)\n",
    "'''\n",
    "\n",
    "\n",
    "# making dataset\n",
    "def making_data_set(d_num):\n",
    "    d_set = np.empty(1)\n",
    "    if file_exist:\n",
    "        tmp = np.load(sys.argv[1])\n",
    "        d_set = np.append(d_set, tmp)\n",
    "    else:\n",
    "        for i in range(int(d_num)):\n",
    "            b0 = int(rd.randint(0, 2, 1))\n",
    "            b1 = int(rd.randint(0, 2, 1))\n",
    "            b2 = int(rd.randint(0, 2, 1))\n",
    "            \n",
    "            x = rd.normal(b0*2 - 1, variance)\n",
    "            y = rd.normal(b1*2 -1, variance)\n",
    "            z = rd.normal(b2*2-1, variance)\n",
    "            \n",
    "            result = b0 + b1 + b2\n",
    "            \n",
    "            rb0 = result % 2\n",
    "            rb1 = int(result/2) % 2\n",
    "            d_set = np.append(d_set, [[x, y, z, rb0, rb1]])\n",
    "            '''x = rd.randint(0, 2, 1)\n",
    "            y = rd.randint(0, 2, 1)\n",
    "            rst = x | y\n",
    "            \n",
    "            d_set = np.append(d_set, [x, y, rst])'''\n",
    "    d_set = np.delete(d_set, 0, axis=0)\n",
    "    d_set = d_set.reshape(-1, 5)\n",
    "    #d_set = d_set.reshape(-1, 3)\n",
    "    return d_set\n",
    "t_data = making_data_set(dataset_num)\n",
    "t_x_data = t_data[:, 0:-2]\n",
    "t_y_data = t_data[:, -2:].reshape(-1, 2)\n",
    "\n",
    "test_data = making_data_set(100)\n",
    "test_x_data = test_data[:, 0:-2]\n",
    "test_y_data = test_data[:, -2:].reshape(-1, 2)\n",
    "\n",
    "'''t_data = making_data_set()\n",
    "t_x_data = t_data[:, 0:-1]\n",
    "t_y_data = t_data[:, -1].reshape(-1, 1)\n",
    "\n",
    "test_data = making_data_set()\n",
    "test_x_data = t_data[:, 0:-1]\n",
    "test_y_data = t_data[:, -1].reshape(-1, 1)'''\n",
    "\n",
    "\n",
    "print(f\"x test data : \\n{test_x_data.shape}\\n y test data : \\n {test_y_data.shape}\\n\")\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class layer_class:\n",
    "    def sigmoid(self, a):\n",
    "        return 1/(1 + np.exp(-a)) \n",
    "    def relu(self, b):\n",
    "        return np.where(b < 0, 0.02*b, b)\n",
    "    def dsigmoid(self, a):\n",
    "        return a * (1 - a)\n",
    "    def drelu(self, a):\n",
    "        return np.where( a<0, -0.02, 1)\n",
    "    w = np.array([]); bias = 'False'; ftn = sigmoid; dftn = dsigmoid; b = np.array([]);  dataflow = np.array([]);  delta = np.array([])\n",
    "    def __init__(self, w, bias='False', activation = 'sigmoid'):\n",
    "        self.w = w\n",
    "        if bias == 'True':\n",
    "            self.bias = 'True'\n",
    "            self.b = np.zeros((1, w.shape[1]))\n",
    "        else:\n",
    "            self.bias = 'False'\n",
    "        if activation == 'sigmoid':\n",
    "            self.ftn = self.sigmoid\n",
    "            self.dftn = self.dsigmoid\n",
    "        elif activation == 'relu':\n",
    "            self.ftn = self.relu\n",
    "            self.dftn = self.drelu\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch = 4\n",
    "learning_rate = 0.02\n",
    "end_learning_rate = 0.02\n",
    "result_mean = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs : 0\t train_loss :0.2417\t test_loss :0.2474\t train_accuracy :53.1%\t test_accuracy :47.5%\n",
      "epochs : 50\t train_loss :0.1508\t test_loss :0.2288\t train_accuracy :69.1%\t test_accuracy :47.5%\n",
      "epochs : 100\t train_loss :0.1238\t test_loss :0.2116\t train_accuracy :73.4%\t test_accuracy :47.5%\n",
      "epochs : 150\t train_loss :0.1071\t test_loss :0.1985\t train_accuracy :77.2%\t test_accuracy :48.5%\n",
      "epochs : 200\t train_loss :0.08866\t test_loss :0.1863\t train_accuracy :79.4%\t test_accuracy :50.0%\n",
      "epochs : 250\t train_loss :0.06792\t test_loss :0.1737\t train_accuracy :89.1%\t test_accuracy :57.0%\n",
      "epochs : 300\t train_loss :0.05186\t test_loss :0.163\t train_accuracy :91.9%\t test_accuracy :60.5%\n",
      "epochs : 350\t train_loss :0.04194\t test_loss :0.1554\t train_accuracy :93.4%\t test_accuracy :62.5%\n",
      "epochs : 400\t train_loss :0.03552\t test_loss :0.15\t train_accuracy :94.4%\t test_accuracy :63.5%\n",
      "epochs : 450\t train_loss :0.03106\t test_loss :0.1461\t train_accuracy :95.0%\t test_accuracy :65.0%\n"
     ]
    }
   ],
   "source": [
    "class NN:\n",
    "    train_set_x, train_set_y, test_set_x, test_set_y, learning_rate, end_learning_rate, activate = np.array([]), np.array([]), np.array(\n",
    "        []), np.array([]), 0, 0, 'sigmoid'\n",
    "    layer, train_loss, test_loss, train_accuracy, test_accuracy = [], [], [], [], []\n",
    "    feature = []\n",
    "    batch = 1\n",
    "    # 추적\n",
    "    weight_hist = []\n",
    "    delta_hist = []\n",
    "    bias_hist = []\n",
    "\n",
    "    def __init__(self, train_set_x, train_set_y, test_set_x, test_set_y, feature, learning_rate=0.01,\\\n",
    "                 end_learning_rate = 0.01, activate='sigmoid', batch=1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.end_learning_rate = end_learning_rate\n",
    "        self.activate = activate\n",
    "        self.train_set_x = train_set_x\n",
    "        self.train_set_y = train_set_y\n",
    "        self.test_set_x = test_set_x\n",
    "        self.test_set_y = test_set_y\n",
    "        self.feature = feature\n",
    "        self.batch = batch\n",
    "        # w initialization sigmoid use xavier initialization  Relu using He initialization\n",
    "        for i, f in enumerate(self.feature):\n",
    "            if i == (len(self.feature) - 1):\n",
    "                break\n",
    "            w = 0\n",
    "            if f[2] is 'sigmoid':\n",
    "                w = rd.randn(f[0], int(self.feature[i + 1][0])) * np.sqrt(1 / (f[0] + self.feature[i + 1][0]))\n",
    "            elif f[2] is 'relu':\n",
    "                w = rd.randn(f[0], int(self.feature[i + 1][0])) * np.sqrt(2 / (f[0] + self.feature[i + 1][0]))\n",
    "            self.layer.append(layer_class(w, f[1], f[2]))\n",
    "\n",
    "    # forwarding\n",
    "    def pri(self):\n",
    "        '''for i in self.layer:\n",
    "            print(i.w)'''\n",
    "        print(\"data predict : \\n\", self.layer[-1].dataflow)\n",
    "\n",
    "    def forwarding(self, x_data, y_data):\n",
    "        for i, k in enumerate(self.layer):\n",
    "            a = np.array([])\n",
    "            if i is 0:\n",
    "                a = np.append(a, np.dot(x_data, k.w))\n",
    "            else:\n",
    "                a = np.append(a, np.dot(self.layer[i - 1].dataflow, k.w))\n",
    "\n",
    "            a = a.reshape(x_data.shape[0], k.w.shape[1])\n",
    "\n",
    "            if k.bias == 'True':\n",
    "                # print(f\"ones : {type(np.ones(1))}  bias : {type(k.b)}\")\n",
    "                a = np.multiply(np.ones((int(x_data.shape[0]), int(k.w.shape[1]))), k.b) + a\n",
    "                # print(a)\n",
    "\n",
    "            k.dataflow = k.ftn(a)\n",
    "        # print(f\"predic output : {self.layer[-1].dataflow.shape}\\n data output : {y_data.shape}\")\n",
    "\n",
    "    def backpropagation(self, x_data, y_data, lr):\n",
    "        for i, L in reversed(list(enumerate(self.layer))):\n",
    "            '''summation {}{j} wij delatj 교재 slide 12p'''\n",
    "            # fully connected layer\n",
    "            L.before_w = L.w\n",
    "            if i is (len(self.layer) - 1):\n",
    "                L.delta = np.multiply((y_data - L.dataflow), L.dftn(L.dataflow))\n",
    "                # print(f\"$$$$$$$$$i :{i}, L.dataflow : {L.dataflow.shape} L.delta : {L.delta.shape}, L.w : {L.w.shape}\")\n",
    "            # else\n",
    "            else:\n",
    "                back_L = self.layer[i + 1]\n",
    "                L.delta = np.multiply(L.dftn(L.dataflow), np.dot(back_L.delta, back_L.before_w.T))\n",
    "                # print(f\"L.delta 구하는 과정\\n\\ni :{i}, L.dataflow : {L.dataflow.shape} back_L.delta : {back_L.delta.shape}, back_L.w : {back_L.w.shape}, L.w. : {L.w.shape}\\n 구하기 end \\n\\n\")\n",
    "\n",
    "            # i가 0 이면 input data가 train_set\n",
    "            if i is 0:\n",
    "                input = x_data\n",
    "            else:\n",
    "                input = self.layer[i - 1].dataflow\n",
    "\n",
    "            '''x_k * delta -> upgrade할 weight '''\n",
    "            upgrade_w = np.zeros(1)\n",
    "            # outer로 한꺼번에 추가후에, reshape로 정렬\n",
    "            for k in range(L.delta.shape[0]):\n",
    "                upgrade_w = np.append(upgrade_w, np.outer(input[k], L.delta[k]))\n",
    "                # print(f\" for {i} layer **********************\\ndelta : \\n{L.delta[k]}\\n input : \\n{input[k]}\\n result : \\n{np.outer(input[k], L.delta[k])}\")\n",
    "            upgrade_w = np.delete(upgrade_w, 0, axis=0)\n",
    "            upgrade_w = upgrade_w.reshape(-1, L.w.shape[0], L.w.shape[1])\n",
    "\n",
    "            \n",
    "\n",
    "            \"\"\"weight update\"\"\"\n",
    "            if L.bias == 'True':\n",
    "                L.b = L.b + np.average(L.delta, axis=0)\n",
    "\n",
    "            \"\"\"update weight\"\"\"\n",
    "            L.w = L.w + np.average(upgrade_w, axis=0) * self.learning_rate\n",
    "\n",
    "    def training(self, epochs):\n",
    "        for i in range(epochs):\n",
    "            for j in range(self.batch):\n",
    "                x_data = self.train_set_x[\n",
    "                         int(len(self.train_set_x) / self.batch) * j: int(len(self.train_set_x) / self.batch) * (j + 1),\n",
    "                         :]\n",
    "                y_data = self.train_set_y[\n",
    "                         int(len(self.train_set_y) / self.batch) * j: int(len(self.train_set_y) / self.batch) * (j + 1),\n",
    "                         :]\n",
    "                lr = self.learning_rate + (self.end_learning_rate - self.learning_rate) / epochs\n",
    "                self.forwarding(x_data, y_data)\n",
    "                self.backpropagation(x_data, y_data, lr)\n",
    "            self.test(self.test_set_x, self.test_set_y)\n",
    "\n",
    "            # print(f\"bias : {self.layer[0].b}\")\n",
    "            if i % 50 == 0:\n",
    "                print(\n",
    "                f\"epochs : {i}\\t train_loss :{self.train_loss[i]:.4}\\t test_loss :{self.test_loss[i]:.4}\\t train_accuracy :{self.train_accuracy[i]:.3}%\\t test_accuracy :{self.test_accuracy[i]:.3}%\")\n",
    "\n",
    "    def plot(self):\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.train_loss, 'b')\n",
    "        plt.plot(self.test_loss, 'r')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.train_accuracy, 'b')\n",
    "        plt.plot(self.test_accuracy, 'r')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.weight_hist)\n",
    "        plt.plot(self.delta_hist)\n",
    "        plt.show()\n",
    "\n",
    "        '''plt.figure()\n",
    "        plt.plot(self.bias_hist)\n",
    "        plt.show()'''\n",
    "\n",
    "    def test(self, x_data, y_data):\n",
    "        #train loss, accuracy 구하기\n",
    "        self.train_loss = np.append(self.train_loss, \\\n",
    "                                    np.average((self.layer[-1].dataflow - \\\n",
    "                                                self.train_set_y[-int(len(self.train_set_y) / self.batch):, :]) ** 2))\n",
    "        \n",
    "        train_result = np.array([self.layer[-1].dataflow > result_mean])\n",
    "        train_cnt = np.equal(self.train_set_y[-int(len(self.train_set_y) / self.batch):, :], train_result)\n",
    "        # print(f\"ny_data : \\n{self.test_set_y}\\n\\n y^ : \\n{self.layer[-1].dataflow}\")\n",
    "        train_correct = np.average(train_cnt) * 100\n",
    "        self.train_accuracy.append(train_correct)\n",
    "        \n",
    "        for i, k in enumerate(self.layer):\n",
    "            a = np.array([])\n",
    "            if i is 0:\n",
    "                a = np.append(a, np.dot(x_data, k.w))\n",
    "            else:\n",
    "                a = np.append(a, np.dot(self.layer[i - 1].dataflow, k.w))\n",
    "\n",
    "            a = a.reshape(self.test_set_x.shape[0], k.w.shape[1])\n",
    "            # print(a.shape)\n",
    "            k.dataflow = k.ftn(a)\n",
    "            \n",
    "            if i == 0:\n",
    "                self.weight_hist.append(k.w.reshape(-1))\n",
    "                self.delta_hist.append(k.delta.reshape(-1))\n",
    "                if k.bias is \"True\":\n",
    "                    self.bias_hist.append(k.b.reshape(-1))\n",
    "                    \n",
    "        self.test_loss = np.append(self.test_loss, np.average((self.layer[-1].dataflow - y_data) ** 2))\n",
    "\n",
    "        # print(self.layer[-1].dataflow)\n",
    "        # result = np.array([self.layer[-1].dataflow > 0.5])\n",
    "        result = np.array([self.layer[-1].dataflow > result_mean])\n",
    "        cnt = np.equal(self.test_set_y, result)\n",
    "        # print(f\"ny_data : \\n{self.test_set_y}\\n\\n y^ : \\n{self.layer[-1].dataflow}\")\n",
    "        correct = np.average(cnt) * 100\n",
    "        self.test_accuracy.append(correct)\n",
    "\n",
    "\n",
    "test = NN(t_x_data, t_y_data, test_x_data, test_y_data, \\\n",
    "          [[3, 'True', 'relu'], [40, 'True', 'relu'],[40, 'True', 'relu'],[40, 'True', 'relu'],[40, 'True', 'sigmoid'],\\\n",
    "           [2, 'False', 'sigmoid']], \\\n",
    "          learning_rate=learning_rate, batch=5)\n",
    "\n",
    "start_time = time.time()\n",
    "test.training(epochs)\n",
    "end_time = time.time()\n",
    "test.pri()\n",
    "\n",
    "print(f\" excutive time : {end_time - start_time}\")\n",
    "test.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(range(10)).reshape(5, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[0:4 , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rd.normal(0, 0.4, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22353198, -0.02148997,  0.08418144, ..., -0.17455141,\n",
       "        0.34263606, -0.61338747])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(x>1, True, np.where(x<-1, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
